{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from IPython.utils.capture import capture_output\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import LSTM, Dense, Input\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "\n",
    "from midi_util import read_midi, produce_song"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Init Plugin\n",
      "Init Graph Optimizer\n",
      "Init Kernel\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "path = os.getcwd() + \"/data/\"\n",
    "print(\"Data path: \", path)\n",
    "\n",
    "midi_file_names = [i for i in os.listdir(path) if i.endswith(\".mid\")]\n",
    "print(\"# of Files Found: \", len(midi_file_names))\n",
    "\n",
    "#hide output, gives many long annoying warnings\n",
    "with capture_output():\n",
    "    note_data_by_file = np.array([read_midi(path+i) for i in midi_file_names], dtype=object)\n",
    "\n",
    "#list comp to flatten\n",
    "flattened_note_data = [element for note_ in note_data_by_file for element in note_]\n",
    "print(\"# of Notes Total: \", len(flattened_note_data))\n",
    "\n",
    "all_unique_notes = list(set(flattened_note_data))\n",
    "print(\"# of Unique Notes: \", len(all_unique_notes))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Data path:  /Users/danielrjohnson/Documents/OneDrive/Programming/AIO/Music-Generation/data/\n",
      "# of Files Found:  35\n",
      "# of Notes Total:  29748\n",
      "# of Unique Notes:  993\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "note_counts = dict(Counter(flattened_note_data))\n",
    "\n",
    "MIN_COUNT = 25\n",
    "frequent_notes = [note_ for note_, count in note_counts.items() if count >= MIN_COUNT]\n",
    "print(\"# of Notes Occurring At Least\", MIN_COUNT, \"Times: \", len(frequent_notes))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "# of Notes Occurring At Least 25 Times:  216\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "freq_note_data = [list(filter(lambda x: x in frequent_notes, midi_data)) for midi_data in note_data_by_file]\n",
    "freq_note_data = np.array(freq_note_data, dtype=object)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "n_timesteps = 32\n",
    "X, y = [], []\n",
    "\n",
    "for notes_of_file in freq_note_data:\n",
    "    for i in range(0, len(notes_of_file) - n_timesteps):\n",
    "        # (n_timesteps) length note sequence\n",
    "        X.append(notes_of_file[i:i + n_timesteps])\n",
    "        # the note following that sequence\n",
    "        y.append(notes_of_file[i + n_timesteps])\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# X = np.array([notes_of_file[i:i + n_timesteps] for i in range(0, len(notes_of_file) - n_timesteps)] )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "unique_x = list(set(X.ravel()))\n",
    "x_note_to_int = dict((note_, number) for number, note_ in enumerate(unique_x))\n",
    "x_seq = np.array([[x_note_to_int[note] for note in row] for row in X])\n",
    "\n",
    "unique_y = list(set(y))\n",
    "y_note_to_int = dict((note_, number) for number, note_ in enumerate(unique_y)) \n",
    "y_seq = np.array([y_note_to_int[note] for note in y])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "x_tr, x_val, y_tr, y_val = train_test_split(x_seq, y_seq, test_size=0.2, random_state=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "inputs = Input((n_timesteps, 1))\n",
    "x = LSTM(128)(inputs)\n",
    "x = Dense(128, activation=\"relu\")(x)\n",
    "output = Dense(128, activation=\"softmax\")(x)\n",
    "\n",
    "model = tf.keras.Model(inputs, output)\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001))\n",
    "model.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 8.00 GB\n",
      "maxCacheSize: 2.67 GB\n",
      "\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32, 1)]           0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 128)               66560     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               16512     \n",
      "=================================================================\n",
      "Total params: 99,584\n",
      "Trainable params: 99,584\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "mc = ModelCheckpoint('models/best_model.h5', monitor='val_loss', mode='min', save_best_only=True, verbose=1)\n",
    "history = model.fit(x=x_tr, y=y_tr,\n",
    "                    batch_size=128, epochs=10, \n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1, callbacks=[mc]\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "158/158 [==============================] - 14s 81ms/step - loss: 2.5967 - accuracy: 0.0234 - val_loss: 2.6451 - val_accuracy: 0.0317\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.64507, saving model to models/best_model.h5\n",
      "Epoch 2/10\n",
      "158/158 [==============================] - 11s 67ms/step - loss: 2.7906 - accuracy: 0.0177 - val_loss: 2.7949 - val_accuracy: 0.0317\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 2.64507\n",
      "Epoch 3/10\n",
      "158/158 [==============================] - 11s 69ms/step - loss: 3.1166 - accuracy: 0.0141 - val_loss: 3.3166 - val_accuracy: 0.0168\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 2.64507\n",
      "Epoch 4/10\n",
      "158/158 [==============================] - 11s 67ms/step - loss: 4.4971 - accuracy: 0.0126 - val_loss: 5.1285 - val_accuracy: 0.0253\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 2.64507\n",
      "Epoch 5/10\n",
      "158/158 [==============================] - 11s 67ms/step - loss: 6.0085 - accuracy: 0.0117 - val_loss: 7.4713 - val_accuracy: 0.0032\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 2.64507\n",
      "Epoch 6/10\n",
      "158/158 [==============================] - 11s 68ms/step - loss: 9.7958 - accuracy: 0.0114 - val_loss: 10.9548 - val_accuracy: 0.0057\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 2.64507\n",
      "Epoch 7/10\n",
      "158/158 [==============================] - 11s 67ms/step - loss: 11.8282 - accuracy: 0.0103 - val_loss: 14.3515 - val_accuracy: 0.0055\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 2.64507\n",
      "Epoch 8/10\n",
      "158/158 [==============================] - 11s 70ms/step - loss: 17.0770 - accuracy: 0.0112 - val_loss: 18.2329 - val_accuracy: 0.0040\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 2.64507\n",
      "Epoch 9/10\n",
      "158/158 [==============================] - 11s 70ms/step - loss: 17.1276 - accuracy: 0.0104 - val_loss: 17.3380 - val_accuracy: 0.0168\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 2.64507\n",
      "Epoch 10/10\n",
      "158/158 [==============================] - 11s 67ms/step - loss: 21.2469 - accuracy: 0.0105 - val_loss: 22.1690 - val_accuracy: 0.0204\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 2.64507\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "produce_song(x_val, n_timesteps, x_note_to_int)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('ml': conda)"
  },
  "interpreter": {
   "hash": "e0289065fd70ee0301126581a02cae4c59a3b78f12d586ce6d502aba513ac9a8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}